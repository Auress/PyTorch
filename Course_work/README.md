### Итоговый проект курса "Фреймворк PyTorch для разработки искусственных нейронных сетей"  
### -- Автор: Шенк Евгений Станиславович  

Стек:  
1. pytorch, cv2, pandas, numpy  

Данные: https://www.kaggle.com/gti-upm/leapgestrecog  
Детектор лица: from facenet_pytorch import MTCNN  
Детектор рук: https://github.com/cansik/yolo-hand-detection  

Задача: Нужно написать приложение, которое будет считывать и выводить кадры с веб-камеры. В процессе считывания определять, что перед камерой находится человек, задетектировав его лицо на кадре. После этого, человек показывает жесты руками, а алгоритм должен считать их и определенным образом реагировать на эти жесты.  

Выполнение:  
Изображения из датасета "leapgestrecog" обработаны (обрезаны, сжаты до 100х100 пикселей и повернуты на углы от -45 до 45 градусов).  
На основе полученного датасета обучена нейронная сеть для определения жестов (10 различных жестов), CNN в 10 эпох.  
Создано приложение для считывания кадров с камеры, детектирующее лицо человека, предсказывающее жест и реагирующее на него (указывает жест и в некоторых случаях переключает цветовые режимы изображения).  

!!! Детектор рук использован из репозитория https://github.com/cansik/yolo-hand-detection, для работы приложения требуется скачать в папку с приложением данный проект, а так же обученные модели в папку ./yolo-hand-detection/models :  
wget https://github.com/cansik/yolo-hand-detection/releases/download/pretrained/cross-hands.cfg  
wget https://github.com/cansik/yolo-hand-detection/releases/download/pretrained/cross-hands.weights  

Результаты:  
Из-за особенностей датасета приложение лучше работает с темным фоном (при освещении "только от монитора" определяет жест довольно точно).
Некоторые положения руки в повороте (как положения из датасета: fist_moved, palm_moved, down) плохо определяются данным детектором руки (возможно из-за камеры низкого разрешения), т.е. рука не распознается как рука.  

Проект содержит:  
1. Course_work.IPYNB - ноутбук с обработкой данных, обучением модели и приложением для камеры (все в одном)  
2. G_recognition.py - скрипт приложения для запуска считывания с камеры  
3. Hand_gesture_recognition_model_100_state_10_epoch.pth - обученная модель  
4. README.md  
